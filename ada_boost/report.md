# 基于SVM的AdaBoost增强手写数字分类报告

## 1. 项目概述

本项目实现了基于SVM的AdaBoost算法用于MNIST手写数字分类任务，主要内容包括：

1. 比较线性核函数的SVM和RBF核函数的SVM的性能
2. 从零实现AdaBoost算法，对比决策树桩和线性SVM作为基分类器的性能

## 2. 数据集与预处理

本实验使用MNIST手写数字数据集，包含28×28像素的手写数字图像。

预处理步骤：
- 将标签转换为整数
- 使用StandardScaler对特征进行标准化
- 将数据集分为训练集和测试集（80%/20%）

## 3. SVM模型实现与比较

### 3.1 线性核与RBF核SVM对比

|  模型  | 准确率 | F1分数 | 训练时间(秒) |
|-------|-------|-------|-------------|
| 线性SVM |       |       |             |
| RBF SVM |       |       |             |

### 3.2 分析

(在此处插入实验结果分析，包括：
- 两种核函数的性能优劣
- 训练时间与模型复杂度的关系
- 可能影响性能的因素)

## 4. AdaBoost算法实现

### 4.1 AdaBoost算法原理

AdaBoost是一种集成学习方法，其核心思想是：
1. 训练一系列弱分类器
2. 每次训练后提高被误分类样本的权重
3. 最终将所有弱分类器加权组合形成强分类器

算法实现步骤：
- 初始化样本权重为均匀分布
- 迭代训练若干个弱分类器
- 计算每个弱分类器的错误率和权重
- 更新样本权重，增加误分类样本的权重
- 最终将所有弱分类器加权组合

### 4.2 基分类器性能对比

|  模型  | 准确率 | F1分数 | 训练时间(秒) |
|-------|-------|-------|-------------|
| AdaBoost+决策树桩 |      |       |             |
| AdaBoost+线性SVM |      |       |             |

### 4.3 学习曲线分析

(在此处插入学习曲线图片和分析)

### 4.4 基分类器优缺点分析

决策树桩作为基分类器：
- 优点：
- 缺点：

线性SVM作为基分类器：
- 优点：
- 缺点：

## 5. 总结与讨论

(总结实验结果，讨论各个模型的适用场景和局限性)

## 6. 参考文献

1. Freund, Y., & Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1), 119-139.
2. Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297.
